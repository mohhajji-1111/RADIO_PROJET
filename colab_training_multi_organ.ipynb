{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04231609",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25575a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monter Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Changer vers le dossier du projet\n",
    "%cd /content/drive/MyDrive/RADIO_PROJET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac551d0",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ V√©rifier GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8ffb03",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Installer d√©pendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee95e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install SimpleITK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77916994",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d52be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Modules du projet\n",
    "from dataset_multi_organ import MultiOrganDataset, compute_class_weights, get_class_distribution\n",
    "from unet_multi_organ import UNetMultiOrgan, count_parameters\n",
    "from train_multi_organ import CombinedLoss, train_model, plot_training_curves\n",
    "\n",
    "print(\"‚úÖ Imports OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a512cb1",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d492b003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam√®tres\n",
    "BATCH_SIZE = 16  # Augmenter si assez de GPU RAM\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_CLASSES = 8\n",
    "NUM_WORKERS = 2\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Chemins\n",
    "BASE_DIR = Path('/content/drive/MyDrive/RADIO_PROJET')\n",
    "DATA_DIR = BASE_DIR / 'DATA' / 'processed'\n",
    "CT_DIR = DATA_DIR / 'normalized'\n",
    "MASK_DIR = DATA_DIR / 'masks_multi_organ'\n",
    "SPLITS_DIR = DATA_DIR / 'splits_rtstruct'\n",
    "CHECKPOINT_DIR = BASE_DIR / 'checkpoints_multi_organ'\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Checkpoint dir: {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4770d87",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Charger donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca1ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les splits\n",
    "print(\"Chargement des splits...\")\n",
    "with open(SPLITS_DIR / 'train.txt', 'r') as f:\n",
    "    train_ids = [line.strip() for line in f.readlines()]\n",
    "with open(SPLITS_DIR / 'val.txt', 'r') as f:\n",
    "    val_ids = [line.strip() for line in f.readlines()]\n",
    "\n",
    "print(f\"‚úÖ Train: {len(train_ids)} patients\")\n",
    "print(f\"‚úÖ Val: {len(val_ids)} patients\")\n",
    "\n",
    "# Cr√©er datasets\n",
    "print(\"\\nCr√©ation des datasets...\")\n",
    "train_dataset = MultiOrganDataset(train_ids, CT_DIR, MASK_DIR)\n",
    "val_dataset = MultiOrganDataset(val_ids, CT_DIR, MASK_DIR)\n",
    "\n",
    "print(f\"‚úÖ Train dataset: {len(train_dataset)} slices\")\n",
    "print(f\"‚úÖ Val dataset: {len(val_dataset)} slices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f06bb7",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Visualiser √©chantillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6dab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser quelques samples\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "LABEL_COLORS = {\n",
    "    0: [0, 0, 0], 1: [255, 0, 0], 2: [255, 165, 0],\n",
    "    3: [0, 255, 255], 4: [0, 191, 255], 5: [255, 0, 255],\n",
    "    6: [255, 255, 0], 7: [0, 255, 0]\n",
    "}\n",
    "\n",
    "for i in range(4):\n",
    "    idx = i * 1000\n",
    "    ct, mask = train_dataset[idx]\n",
    "    \n",
    "    ct_np = ct.squeeze().numpy()\n",
    "    mask_np = mask.numpy()\n",
    "    \n",
    "    # Cr√©er masque RGB\n",
    "    mask_rgb = np.zeros((*mask_np.shape, 3), dtype=np.uint8)\n",
    "    for label, color in LABEL_COLORS.items():\n",
    "        mask_rgb[mask_np == label] = color\n",
    "    \n",
    "    # CT\n",
    "    axes[0, i].imshow(ct_np, cmap='gray')\n",
    "    axes[0, i].set_title(f'Sample {i+1} - CT', fontsize=12)\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Masque\n",
    "    axes[1, i].imshow(mask_rgb)\n",
    "    unique_labels = np.unique(mask_np)\n",
    "    axes[1, i].set_title(f'{len(unique_labels)-1} organes', fontsize=12)\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('samples_preview.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úÖ Visualisation sauvegard√©e: samples_preview.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841d21d0",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Calculer class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef94d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Cette √©tape peut prendre 10-15 minutes\n",
    "# Si tu as d√©j√† calcul√© les weights, charge-les depuis un fichier JSON\n",
    "\n",
    "import os\n",
    "\n",
    "weights_file = CHECKPOINT_DIR / 'class_weights.json'\n",
    "\n",
    "if weights_file.exists():\n",
    "    print(\"Chargement des class weights depuis fichier...\")\n",
    "    with open(weights_file, 'r') as f:\n",
    "        weights_list = json.load(f)\n",
    "    class_weights = torch.tensor(weights_list, dtype=torch.float32).to(DEVICE)\n",
    "else:\n",
    "    print(\"Calcul des class weights (peut prendre 10-15 min)...\")\n",
    "    class_counts = get_class_distribution(train_dataset)\n",
    "    class_weights = compute_class_weights(class_counts, method='sqrt_inverse')\n",
    "    \n",
    "    # Sauvegarder pour r√©utilisation\n",
    "    with open(weights_file, 'w') as f:\n",
    "        json.dump(class_weights.tolist(), f)\n",
    "    \n",
    "    class_weights = class_weights.to(DEVICE)\n",
    "\n",
    "print(\"\\nClass weights:\")\n",
    "label_names = ['Background', 'GTV', 'PTV', 'Poumon_D', 'Poumon_G', 'Coeur', 'Oesophage', 'Moelle']\n",
    "for i, (name, weight) in enumerate(zip(label_names, class_weights)):\n",
    "    print(f\"  {i}: {name:12s} = {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f702766",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Cr√©er DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c02f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Train batches: {len(train_loader)}\")\n",
    "print(f\"‚úÖ Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5e037b",
   "metadata": {},
   "source": [
    "## üîü Cr√©er mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c64fa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetMultiOrgan(n_channels=1, n_classes=NUM_CLASSES, bilinear=False)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "num_params = count_parameters(model)\n",
    "model_size_mb = num_params * 4 / (1024**2)\n",
    "\n",
    "print(f\"‚úÖ Mod√®le cr√©√©\")\n",
    "print(f\"  Param√®tres: {num_params:,}\")\n",
    "print(f\"  Taille: {model_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c92e02",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Loss et Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b30631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss combin√©e: CrossEntropy + Dice\n",
    "criterion = CombinedLoss(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    class_weights=class_weights,\n",
    "    ce_weight=0.5,\n",
    "    dice_weight=0.5\n",
    ")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(\"‚úÖ Loss: CombinedLoss (CE + Dice)\")\n",
    "print(\"‚úÖ Optimizer: Adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939b60e5",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ üöÄ ENTRA√éNEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0e9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"D√âBUT DE L'ENTRA√éNEMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    save_dir=str(CHECKPOINT_DIR),\n",
    "    early_stopping_patience=10\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ ENTRA√éNEMENT TERMIN√â!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6dd517",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£3Ô∏è‚É£ Visualiser courbes d'entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af7c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curves(history, save_path=str(CHECKPOINT_DIR / \"training_curves.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2287324f",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£4Ô∏è‚É£ Charger meilleur mod√®le et visualiser pr√©dictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51faaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le meilleur mod√®le\n",
    "checkpoint = torch.load(CHECKPOINT_DIR / 'best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Meilleur mod√®le charg√© (Epoch {checkpoint['epoch']})\")\n",
    "print(f\"   Val Dice: {checkpoint['val_dice']:.4f}\")\n",
    "\n",
    "# Visualiser pr√©dictions\n",
    "fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(4):\n",
    "        idx = i * 1000\n",
    "        ct, mask_true = val_dataset[idx]\n",
    "        \n",
    "        # Pr√©diction\n",
    "        ct_batch = ct.unsqueeze(0).to(DEVICE)\n",
    "        logits = model(ct_batch)\n",
    "        mask_pred = torch.argmax(logits, dim=1).squeeze().cpu().numpy()\n",
    "        \n",
    "        ct_np = ct.squeeze().numpy()\n",
    "        mask_true_np = mask_true.numpy()\n",
    "        \n",
    "        # Cr√©er masques RGB\n",
    "        mask_true_rgb = np.zeros((*mask_true_np.shape, 3), dtype=np.uint8)\n",
    "        mask_pred_rgb = np.zeros((*mask_pred.shape, 3), dtype=np.uint8)\n",
    "        for label, color in LABEL_COLORS.items():\n",
    "            mask_true_rgb[mask_true_np == label] = color\n",
    "            mask_pred_rgb[mask_pred == label] = color\n",
    "        \n",
    "        # CT\n",
    "        axes[0, i].imshow(ct_np, cmap='gray')\n",
    "        axes[0, i].set_title(f'Sample {i+1} - CT', fontsize=12)\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Ground Truth\n",
    "        axes[1, i].imshow(mask_true_rgb)\n",
    "        axes[1, i].set_title('Ground Truth', fontsize=12)\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        # Pr√©diction\n",
    "        axes[2, i].imshow(mask_pred_rgb)\n",
    "        axes[2, i].set_title('Pr√©diction', fontsize=12)\n",
    "        axes[2, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CHECKPOINT_DIR / 'predictions_samples.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úÖ Visualisation sauvegard√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1ec923",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£5Ô∏è‚É£ üìä R√©sum√© final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"R√âSUM√â FINAL\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìÅ Dataset:\")\n",
    "print(f\"   Train: {len(train_ids)} patients, {len(train_dataset):,} slices\")\n",
    "print(f\"   Val: {len(val_ids)} patients, {len(val_dataset):,} slices\")\n",
    "\n",
    "print(f\"\\nüéØ Mod√®le:\")\n",
    "print(f\"   Architecture: U-Net multi-classes\")\n",
    "print(f\"   Param√®tres: {num_params:,}\")\n",
    "print(f\"   Classes: {NUM_CLASSES}\")\n",
    "\n",
    "print(f\"\\nüèÜ Meilleur mod√®le:\")\n",
    "print(f\"   Epoch: {checkpoint['epoch']}\")\n",
    "print(f\"   Val Dice: {checkpoint['val_dice']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä Dice par organe:\")\n",
    "for c, score in checkpoint['val_dice_per_class'].items():\n",
    "    print(f\"   {label_names[c]:12s}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nüíæ Fichiers sauvegard√©s:\")\n",
    "print(f\"   {CHECKPOINT_DIR / 'best_model.pth'}\")\n",
    "print(f\"   {CHECKPOINT_DIR / 'training_history.json'}\")\n",
    "print(f\"   {CHECKPOINT_DIR / 'training_curves.png'}\")\n",
    "print(f\"   {CHECKPOINT_DIR / 'predictions_samples.png'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ PROJET TERMIN√â!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
