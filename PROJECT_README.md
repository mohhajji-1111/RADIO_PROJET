# NSCLC-Radiomics Lung Tumor Segmentation Project

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ¯ Project Overview

This project implements an end-to-end deep learning pipeline for **lung tumor segmentation** using the NSCLC-Radiomics dataset. The pipeline includes:

- **DICOM to NIfTI conversion** (CT scans + RTSTRUCT contours)
- **Data preprocessing and normalization** (HU windowing, resampling, augmentation)
- **U-Net model training** (PyTorch implementation)
- **Comprehensive evaluation** (Dice, IoU, Hausdorff distance)
- **Visualization and analysis** (2D slices, 3D rendering, overlay comparisons)

---

## ğŸ“ Project Structure

```
RADIO_PROJET/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ NSCLC-Radiomics/          # Raw DICOM data (CT + RTSTRUCT)
â”‚   â”œâ”€â”€ processed/                 # Processed NIfTI files
â”‚   â”‚   â”œâ”€â”€ images_nifti/          # Converted CT volumes
â”‚   â”‚   â”œâ”€â”€ masks_nifti/           # Extracted binary masks
â”‚   â”‚   â”œâ”€â”€ normalized/            # Normalized data
â”‚   â”‚   â””â”€â”€ splits/                # Train/val/test split information
â”‚   â””â”€â”€ results/                   # Training outputs
â”‚       â”œâ”€â”€ predictions/           # Model predictions
â”‚       â”œâ”€â”€ metrics/               # Evaluation metrics
â”‚       â”œâ”€â”€ models/                # Saved model checkpoints
â”‚       â””â”€â”€ visualizations/        # Plots and figures
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_preprocessing.ipynb     # Data preprocessing pipeline
â”‚   â”œâ”€â”€ 02_training_unet.ipynb     # Model training
â”‚   â”œâ”€â”€ 03_evaluation.ipynb        # Model evaluation
â”‚   â””â”€â”€ 04_visualization.ipynb     # Results visualization
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ convert_dicom_to_nifti.py    # DICOM â†’ NIfTI conversion
â”‚   â”‚   â”œâ”€â”€ extract_mask_from_rtstruct.py # RTSTRUCT â†’ binary mask
â”‚   â”‚   â”œâ”€â”€ normalize_data.py             # Data normalization
â”‚   â”‚   â”œâ”€â”€ split_dataset.py              # Train/val/test splitting
â”‚   â”‚   â””â”€â”€ utils_dicom.py                # DICOM utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ dataset.py              # PyTorch Dataset class
â”‚   â”‚   â”œâ”€â”€ unet_model.py           # U-Net architecture
â”‚   â”‚   â”œâ”€â”€ train.py                # Training loop
â”‚   â”‚   â”œâ”€â”€ evaluate.py             # Evaluation metrics
â”‚   â”‚   â””â”€â”€ visualize.py            # Visualization utilities
â”‚   â”‚
â”‚   â””â”€â”€ config/
â”‚       â”œâ”€â”€ paths.yaml              # Path configurations
â”‚       â”œâ”€â”€ params.yaml             # Hyperparameters
â”‚       â””â”€â”€ environment.yaml        # Conda environment
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocess_all.py           # Run complete preprocessing
â”‚   â”œâ”€â”€ train_unet.py               # Train U-Net model
â”‚   â””â”€â”€ evaluate_unet.py            # Evaluate trained model
â”‚
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # This file
â””â”€â”€ .gitignore                      # Git ignore rules
```

---

## ğŸš€ Quick Start

### 1. Environment Setup

#### Option A: Using Conda (Recommended)
```bash
# Create environment from YAML
conda env create -f src/config/environment.yaml

# Activate environment
conda activate nsclc-seg
```

#### Option B: Using pip
```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure Paths

Edit `src/config/paths.yaml` to match your local directory structure:

```yaml
project_root: "C:/Users/HP/Desktop/RADIO_PROJET"
raw_data:
  nsclc_radiomics: "C:/Users/HP/Desktop/RADIO_PROJET/DATA/NSCLC-Radiomics"
```

### 3. Run Preprocessing

```bash
# Run complete preprocessing pipeline
python scripts/preprocess_all.py --config src/config/params.yaml

# Or run individual steps
python scripts/preprocess_all.py --step convert    # DICOM â†’ NIfTI
python scripts/preprocess_all.py --step extract   # Extract masks
python scripts/preprocess_all.py --step normalize # Normalize data
python scripts/preprocess_all.py --step split     # Create splits
```

### 4. Train Model

```bash
# Train U-Net model
python scripts/train_unet.py --config src/config/params.yaml

# Resume from checkpoint
python scripts/train_unet.py --config src/config/params.yaml --resume path/to/checkpoint.pth
```

### 5. Evaluate Model

```bash
# Evaluate on test set
python scripts/evaluate_unet.py --config src/config/params.yaml --checkpoint path/to/best_model.pth

# Evaluate on validation set
python scripts/evaluate_unet.py --config src/config/params.yaml --checkpoint path/to/best_model.pth --split val
```

---

## ğŸ“Š Dataset Information

### NSCLC-Radiomics Dataset

- **Source**: The Cancer Imaging Archive (TCIA)
- **Patients**: 422 non-small cell lung cancer patients
- **Modalities**: CT scans + RTSTRUCT (radiation therapy structure sets)
- **Task**: Segment lung tumors (GTV, CTV, PTV) from CT images

### Data Processing Pipeline

1. **DICOM Loading**: Read CT series and RTSTRUCT files
2. **Resampling**: Standardize voxel spacing to 1Ã—1Ã—1 mmÂ³
3. **HU Windowing**: Clip Hounsfield Units to [-1000, 400]
4. **Normalization**: Z-score normalization per volume
5. **Resizing**: Resize 2D slices to 256Ã—256 pixels
6. **Splitting**: 70% train, 15% validation, 15% test

---

## ğŸ§  Model Architecture

### U-Net

Classic U-Net architecture with:
- **Encoder**: 4 downsampling blocks (64 â†’ 128 â†’ 256 â†’ 512 features)
- **Bottleneck**: 1024 features
- **Decoder**: 4 upsampling blocks with skip connections
- **Output**: Sigmoid activation for binary segmentation

**Total Parameters**: ~31 million

### Training Configuration

```yaml
Optimizer: Adam (lr=0.001)
Loss: Combined Dice + BCE (50/50 weight)
Batch Size: 8
Epochs: 100
Scheduler: ReduceLROnPlateau
Early Stopping: Patience 20 epochs
```

---

## ğŸ“ˆ Evaluation Metrics

- **Dice Coefficient**: Overlap between prediction and ground truth
- **IoU (Jaccard Index)**: Intersection over Union
- **Precision**: True positives / (True positives + False positives)
- **Recall**: True positives / (True positives + False negatives)
- **Hausdorff Distance**: Maximum boundary distance
- **Surface Distance**: Average boundary distance

---

## ğŸ““ Jupyter Notebooks

Interactive notebooks for exploration:

1. **01_preprocessing.ipynb**: Visualize data preprocessing steps
2. **02_training_unet.ipynb**: Interactive model training
3. **03_evaluation.ipynb**: Detailed evaluation analysis
4. **04_visualization.ipynb**: Advanced visualization techniques

---

## ğŸ”§ Configuration

### Key Configuration Files

#### `params.yaml` - Hyperparameters
- Preprocessing settings (HU window, spacing, size)
- Augmentation parameters
- Model architecture settings
- Training hyperparameters
- Evaluation metrics

#### `paths.yaml` - Directory Paths
- Raw data locations
- Processed data directories
- Output directories
- Model checkpoint paths

---

## ğŸ“ Development Phases

### âœ… Phase 1: Project Structure (COMPLETE)
- Directory structure created
- Configuration files generated
- Template files created
- Documentation written

### ğŸ”„ Phase 2: DICOM â†’ NIfTI Conversion (NEXT)
- Implement DICOM loading
- RTSTRUCT mask extraction
- NIfTI conversion
- Batch processing

### ğŸ”„ Phase 3: Data Normalization + Splitting
- HU clipping and normalization
- Image resizing
- Train/val/test splitting

### ğŸ”„ Phase 4: PyTorch Dataset + Dataloader
- Custom Dataset class
- Data augmentation
- Dataloader creation

### ğŸ”„ Phase 5: U-Net Implementation
- Model architecture
- Loss functions
- Parameter counting

### ğŸ”„ Phase 6: Training Pipeline
- Training loop
- Validation loop
- Checkpointing
- TensorBoard logging

### ğŸ”„ Phase 7: Evaluation + Visualization
- Metrics computation
- Prediction visualization
- 3D rendering

### ğŸ”„ Phase 8: Final Report
- Scientific documentation
- Results analysis
- Future improvements

---

## ğŸ› ï¸ Technologies Used

- **Python 3.10+**
- **PyTorch 2.0+**: Deep learning framework
- **SimpleITK**: Medical image processing
- **pydicom**: DICOM file handling
- **nibabel**: NIfTI file I/O
- **numpy, scipy**: Numerical computing
- **matplotlib, seaborn**: Visualization
- **pandas**: Data management
- **tensorboard**: Training monitoring

---

## ğŸ“š References

1. Ronneberger, O., Fischer, P., & Brox, T. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation. *MICCAI*.

2. Aerts, H. J., et al. (2014). Decoding tumour phenotype by noninvasive imaging using a quantitative radiomics approach. *Nature Communications*.

3. TCIA NSCLC-Radiomics Dataset: https://doi.org/10.7937/K9/TCIA.2015.PF0M9REI

---

## ğŸ‘¥ Authors

**Medical Imaging Team**  
November 2025

---

## ğŸ“„ License

This project is licensed under the MIT License.

---

## ğŸ™ Acknowledgments

- The Cancer Imaging Archive (TCIA) for providing the NSCLC-Radiomics dataset
- The medical imaging community for open-source tools and libraries

---

## ğŸ“ Support

For questions or issues:
1. Check documentation in `docs/` folder
2. Review Jupyter notebooks for examples
3. Open an issue on GitHub

---

**Happy Segmenting! ğŸ¥ğŸ§ **
