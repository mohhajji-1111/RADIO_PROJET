{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8df98f62",
   "metadata": {},
   "source": [
    "## üìÇ Cell 1: Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee23b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Dataset paths\n",
    "DATA_ROOT = Path('/kaggle/input/nsclc-multiorgan-segmentation')\n",
    "CT_DIR = DATA_ROOT / 'normalized_ct'\n",
    "MASKS_DIR = DATA_ROOT / 'normalized_masks'\n",
    "CODE_DIR = DATA_ROOT / 'code'\n",
    "\n",
    "# Add code to Python path\n",
    "sys.path.append(str(CODE_DIR))\n",
    "\n",
    "# Verify dataset\n",
    "if DATA_ROOT.exists():\n",
    "    print(\"‚úÖ Dataset found!\")\n",
    "    ct_files = list(CT_DIR.glob('*.nii'))\n",
    "    mask_files = list(MASKS_DIR.glob('*.nii'))\n",
    "    print(f\"‚úÖ {len(ct_files)} CT files\")\n",
    "    print(f\"‚úÖ {len(mask_files)} Mask files\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset not found!\")\n",
    "    print(\"Please add dataset: + Add Data ‚Üí Your Datasets ‚Üí nsclc-multiorgan-segmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c070b6e",
   "metadata": {},
   "source": [
    "## üì¶ Cell 2: Install Dependencies & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1756bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install SimpleITK if needed\n",
    "!pip install SimpleITK -q\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "\n",
    "print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0badab0",
   "metadata": {},
   "source": [
    "## üìä Cell 3: Dataset Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f2d556",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecc5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOrganDataset(Dataset):\n",
    "    def __init__(self, ct_dir, masks_dir, transform=None):\n",
    "        self.ct_dir = Path(ct_dir)\n",
    "        self.masks_dir = Path(masks_dir)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get all CT files\n",
    "        self.ct_files = sorted(self.ct_dir.glob('*.nii'))\n",
    "        \n",
    "        # Build patient list and slice mapping\n",
    "        self.samples = []\n",
    "        \n",
    "        print(f\"Loading {len(self.ct_files)} patients...\")\n",
    "        for ct_path in tqdm(self.ct_files):  # All 158 patients for full training\n",
    "            patient_id = ct_path.stem.replace('_ct_normalized', '')\n",
    "            mask_path = self.masks_dir / f\"{patient_id}_mask_normalized.nii\"\n",
    "            \n",
    "            if not mask_path.exists():\n",
    "                continue\n",
    "            \n",
    "            # Load to get number of slices\n",
    "            ct_img = sitk.ReadImage(str(ct_path))\n",
    "            ct_array = sitk.GetArrayFromImage(ct_img)\n",
    "            \n",
    "            # Add each slice as a sample\n",
    "            for slice_idx in range(ct_array.shape[0]):\n",
    "                self.samples.append({\n",
    "                    'ct_path': ct_path,\n",
    "                    'mask_path': mask_path,\n",
    "                    'slice_idx': slice_idx\n",
    "                })\n",
    "        \n",
    "        print(f\"‚úÖ Total slices: {len(self.samples)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Load CT and mask\n",
    "        ct_img = sitk.ReadImage(str(sample['ct_path']))\n",
    "        mask_img = sitk.ReadImage(str(sample['mask_path']))\n",
    "        \n",
    "        ct_array = sitk.GetArrayFromImage(ct_img)\n",
    "        mask_array = sitk.GetArrayFromImage(mask_img)\n",
    "        \n",
    "        # Get slice\n",
    "        ct_slice = ct_array[sample['slice_idx']]\n",
    "        mask_slice = mask_array[sample['slice_idx']]\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        ct_tensor = torch.from_numpy(ct_slice).unsqueeze(0).float()\n",
    "        mask_tensor = torch.from_numpy(mask_slice).long()\n",
    "        \n",
    "        return {\n",
    "            'image': ct_tensor,\n",
    "            'mask': mask_tensor\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Dataset class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64845c96",
   "metadata": {},
   "source": [
    "## üß† Cell 4: U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetMultiOrgan(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.enc4 = self.conv_block(256, 512)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = self.conv_block(512, 1024)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.dec4 = self.conv_block(1024, 512)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.dec3 = self.conv_block(512, 256)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.dec2 = self.conv_block(256, 128)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = self.conv_block(128, 64)\n",
    "        \n",
    "        # Output\n",
    "        self.out = nn.Conv2d(64, out_channels, 1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "    \n",
    "    def conv_block(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        e4 = self.enc4(self.pool(e3))\n",
    "        \n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "        \n",
    "        # Decoder\n",
    "        d4 = self.dec4(torch.cat([self.up4(b), e4], dim=1))\n",
    "        d3 = self.dec3(torch.cat([self.up3(d4), e3], dim=1))\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), e2], dim=1))\n",
    "        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1))\n",
    "        \n",
    "        return self.out(d1)\n",
    "\n",
    "print(\"‚úÖ U-Net model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace07aa",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Cell 5: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096c1459",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'batch_size': 8,\n",
    "    'num_epochs': 50,  # Full training for best results\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_workers': 2,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'patience': 10,  # Increased patience for full training\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb2e3d0",
   "metadata": {},
   "source": [
    "## üìä Cell 6: Create Datasets & Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efb8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating dataset...\")\n",
    "full_dataset = MultiOrganDataset(CT_DIR, MASKS_DIR)\n",
    "\n",
    "# Split: 80% train, 20% val\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    full_dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Train: {len(train_dataset)} slices\")\n",
    "print(f\"‚úÖ Val: {len(val_dataset)} slices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b906efc",
   "metadata": {},
   "source": [
    "## üéØ Cell 7: Initialize Model & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = UNetMultiOrgan(in_channels=1, out_channels=8).to(CONFIG['device'])\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"‚úÖ Model: {num_params:,} parameters\")\n",
    "\n",
    "# Loss functions\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        pred = torch.softmax(pred, dim=1)\n",
    "        target_one_hot = torch.nn.functional.one_hot(target, 8).permute(0, 3, 1, 2).float()\n",
    "        \n",
    "        intersection = (pred * target_one_hot).sum(dim=(2, 3))\n",
    "        union = pred.sum(dim=(2, 3)) + target_one_hot.sum(dim=(2, 3))\n",
    "        dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
    "        return 1.0 - dice.mean()\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        self.dice = DiceLoss()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        return 0.5 * self.ce(pred, target) + 0.5 * self.dice(pred, target)\n",
    "\n",
    "criterion = CombinedLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'])\n",
    "\n",
    "print(\"‚úÖ Loss: CombinedLoss (CE + Dice)\")\n",
    "print(\"‚úÖ Optimizer: Adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6195c6f",
   "metadata": {},
   "source": [
    "## üîÑ Cell 8: Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6281490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for batch in pbar:\n",
    "        images = batch['image'].to(device)\n",
    "        masks = batch['mask'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc='Validation')\n",
    "        for batch in pbar:\n",
    "            images = batch['image'].to(device)\n",
    "            masks = batch['mask'].to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "print(\"‚úÖ Training functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe7c0c",
   "metadata": {},
   "source": [
    "## üöÄ Cell 9: Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aebb352",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üöÄ STARTING TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "history = {'train_loss': [], 'val_loss': []}\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(CONFIG['num_epochs']):\n",
    "    print(f\"\\nüìä Epoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
    "    \n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, CONFIG['device'])\n",
    "    val_loss = validate(model, val_loader, criterion, CONFIG['device'])\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), '/kaggle/working/best_model.pth')\n",
    "        print(\"‚úÖ Saved best model\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= CONFIG['patience']:\n",
    "            print(f\"‚ö†Ô∏è Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"‚úÖ TRAINING COMPLETED\")\n",
    "print(f\"Best Val Loss: {best_val_loss:.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d57fe1",
   "metadata": {},
   "source": [
    "## üìä Cell 10: Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "plt.plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('/kaggle/working/training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìä Best Val Loss: {min(history['val_loss']):.4f}\")\n",
    "print(f\"üìä Final Train Loss: {history['train_loss'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628d49be",
   "metadata": {},
   "source": [
    "## üé® Cell 11: Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712db6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('/kaggle/working/best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Get 4 samples\n",
    "val_samples = [val_dataset[i] for i in range(0, len(val_dataset), len(val_dataset)//4)][:4]\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(12, 16))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, sample in enumerate(val_samples):\n",
    "        image = sample['image'].unsqueeze(0).to(CONFIG['device'])\n",
    "        mask_true = sample['mask'].numpy()\n",
    "        \n",
    "        # Prediction\n",
    "        output = model(image)\n",
    "        mask_pred = torch.argmax(output, dim=1).cpu().numpy()[0]\n",
    "        \n",
    "        # Plot\n",
    "        axes[idx, 0].imshow(image.cpu().squeeze(), cmap='gray')\n",
    "        axes[idx, 0].set_title('CT Scan')\n",
    "        axes[idx, 0].axis('off')\n",
    "        \n",
    "        axes[idx, 1].imshow(mask_true, cmap='tab10', vmin=0, vmax=7)\n",
    "        axes[idx, 1].set_title('Ground Truth')\n",
    "        axes[idx, 1].axis('off')\n",
    "        \n",
    "        axes[idx, 2].imshow(mask_pred, cmap='tab10', vmin=0, vmax=7)\n",
    "        axes[idx, 2].set_title('Prediction')\n",
    "        axes[idx, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/kaggle/working/predictions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualizations saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0798adb6",
   "metadata": {},
   "source": [
    "## üíæ Cell 12: Summary & Download Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08233980",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"üìä TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dataset: {len(train_dataset)} train, {len(val_dataset)} val slices\")\n",
    "print(f\"Model: U-Net ({num_params:,} parameters)\")\n",
    "print(f\"Best Val Loss: {best_val_loss:.4f}\")\n",
    "print(f\"Epochs: {len(history['train_loss'])}\")\n",
    "print(\"\\nüì• Output files:\")\n",
    "print(\"  ‚úÖ /kaggle/working/best_model.pth\")\n",
    "print(\"  ‚úÖ /kaggle/working/training_curves.png\")\n",
    "print(\"  ‚úÖ /kaggle/working/predictions.png\")\n",
    "print(\"\\nüí° Download files from Output section (sidebar right)\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
