{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "206b610d",
   "metadata": {},
   "source": [
    "## üì¶ Installation des d√©pendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7224d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q SimpleITK nibabel tqdm scikit-learn seaborn\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6010cc6b",
   "metadata": {},
   "source": [
    "## üìÅ Upload des donn√©es\n",
    "\n",
    "**Option 1: Upload depuis PC**\n",
    "- Zippe `data/processed/normalized/` sur ton PC\n",
    "- Upload le zip ici\n",
    "- D√©compresse\n",
    "\n",
    "**Option 2: Google Drive**\n",
    "- Monte Google Drive\n",
    "- Place les donn√©es dans Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa5e7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# üì¶ CHARGER DONN√âES DEPUIS GOOGLE DRIVE\n",
    "# ==================================================\n",
    "\n",
    "from google.colab import drive\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Monter Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Chemin du ZIP dans Drive (utilise colab_data.zip - le fichier complet)\n",
    "ZIP_PATH = '/content/drive/MyDrive/colab_data.zip'\n",
    "\n",
    "# V√©rifier si le ZIP existe\n",
    "if not os.path.exists(ZIP_PATH):\n",
    "    print(f\"‚ùå Fichier non trouv√©: {ZIP_PATH}\")\n",
    "    print(\"\\nüí° Instructions:\")\n",
    "    print(\"   1. Upload colab_data.zip dans Google Drive\")\n",
    "    print(\"   2. Place-le dans 'Mon Drive' (MyDrive)\")\n",
    "    print(\"   3. Relance cette cellule\")\n",
    "else:\n",
    "    # Extraire dans Colab\n",
    "    print(\"üì¶ Extraction du ZIP en cours...\")\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall('/content/data')\n",
    "    \n",
    "    print(\"‚úÖ Extraction termin√©e!\")\n",
    "    \n",
    "    # D√©finir les chemins\n",
    "    DATA_ROOT = '/content/data/normalized'\n",
    "    SPLITS_DIR = '/content/data/splits'\n",
    "    \n",
    "    # V√©rifier la structure\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üìä V√âRIFICATION DES DONN√âES\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Compter fichiers normalis√©s\n",
    "    ct_files = [f for f in os.listdir(DATA_ROOT) if f.endswith('_ct_normalized.nii.gz')]\n",
    "    mask_files = [f for f in os.listdir(DATA_ROOT) if f.endswith('_mask_normalized.nii.gz')]\n",
    "    \n",
    "    print(f\"üìÅ Donn√©es normalis√©es:\")\n",
    "    print(f\"   CT scans: {len(ct_files)}\")\n",
    "    print(f\"   Masks: {len(mask_files)}\")\n",
    "    print()\n",
    "    \n",
    "    # V√©rifier splits\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_file = os.path.join(SPLITS_DIR, f'{split}.txt')\n",
    "        if os.path.exists(split_file):\n",
    "            with open(split_file, 'r') as f:\n",
    "                patient_ids = [line.strip() for line in f if line.strip()]\n",
    "            print(f\"   {split.capitalize()}: {len(patient_ids)} patients\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå {split}.txt NOT FOUND!\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Donn√©es pr√™tes pour l'entra√Ænement!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df27dbe4",
   "metadata": {},
   "source": [
    "## üèóÔ∏è PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f721243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# üìä DATASET CLASS (adapt√© pour structure plate avec splits)\n",
    "# ==================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import SimpleITK as sitk\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Tuple, List\n",
    "\n",
    "class NSCLCDataset(Dataset):\n",
    "    \"\"\"Dataset pour les images CT et masques de segmentation.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data_root: str,\n",
    "        split_file: str,\n",
    "        mode: str = 'slice',\n",
    "        transform=None,\n",
    "        cache: bool = False\n",
    "    ):\n",
    "        self.data_root = Path(data_root)\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.cache = cache\n",
    "        self.cached_data = {} if cache else None\n",
    "        \n",
    "        # Lire les patient IDs depuis le fichier split\n",
    "        with open(split_file, 'r') as f:\n",
    "            self.patient_ids = [line.strip() for line in f if line.strip()]\n",
    "        \n",
    "        # Construire les paires CT/mask\n",
    "        self.ct_files = [self.data_root / f\"{pid}_ct_normalized.nii.gz\" for pid in self.patient_ids]\n",
    "        self.mask_files = [self.data_root / f\"{pid}_mask_normalized.nii.gz\" for pid in self.patient_ids]\n",
    "        \n",
    "        # V√©rifier que tous les fichiers existent\n",
    "        for ct_file, mask_file in zip(self.ct_files, self.mask_files):\n",
    "            if not ct_file.exists():\n",
    "                raise FileNotFoundError(f\"CT file not found: {ct_file}\")\n",
    "            if not mask_file.exists():\n",
    "                raise FileNotFoundError(f\"Mask file not found: {mask_file}\")\n",
    "        \n",
    "        # Construire index slice-wise\n",
    "        if self.mode == 'slice':\n",
    "            self.slice_index = []\n",
    "            for idx, ct_file in enumerate(self.ct_files):\n",
    "                img = sitk.ReadImage(str(ct_file))\n",
    "                n_slices = img.GetSize()[2]\n",
    "                for slice_idx in range(n_slices):\n",
    "                    self.slice_index.append((idx, slice_idx))\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        if self.mode == 'slice':\n",
    "            return len(self.slice_index)\n",
    "        return len(self.ct_files)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        if self.mode == 'slice':\n",
    "            volume_idx, slice_idx = self.slice_index[idx]\n",
    "        else:\n",
    "            volume_idx = idx\n",
    "            slice_idx = None\n",
    "        \n",
    "        # Cache\n",
    "        cache_key = (volume_idx, slice_idx)\n",
    "        if self.cache and cache_key in self.cached_data:\n",
    "            return self.cached_data[cache_key]\n",
    "        \n",
    "        # Charger\n",
    "        image = sitk.GetArrayFromImage(sitk.ReadImage(str(self.ct_files[volume_idx])))\n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(str(self.mask_files[volume_idx])))\n",
    "        \n",
    "        if self.mode == 'slice':\n",
    "            image = image[slice_idx]\n",
    "            mask = mask[slice_idx]\n",
    "        \n",
    "        # Convertir en tenseurs\n",
    "        image = torch.from_numpy(image).float().unsqueeze(0)\n",
    "        mask = torch.from_numpy(mask).float().unsqueeze(0)\n",
    "        \n",
    "        # Transformation\n",
    "        if self.transform:\n",
    "            image, mask = self.transform(image, mask)\n",
    "        \n",
    "        if self.cache:\n",
    "            self.cached_data[cache_key] = (image, mask)\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "def create_dataloaders(\n",
    "    data_root: str,\n",
    "    splits_dir: str,\n",
    "    batch_size: int = 8,\n",
    "    num_workers: int = 2,\n",
    "    mode: str = 'slice'\n",
    ") -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
    "    \"\"\"Cr√©e les DataLoaders train/val/test depuis les fichiers split.\"\"\"\n",
    "    \n",
    "    train_dataset = NSCLCDataset(\n",
    "        data_root=data_root,\n",
    "        split_file=f\"{splits_dir}/train.txt\",\n",
    "        mode=mode\n",
    "    )\n",
    "    \n",
    "    val_dataset = NSCLCDataset(\n",
    "        data_root=data_root,\n",
    "        split_file=f\"{splits_dir}/val.txt\",\n",
    "        mode=mode\n",
    "    )\n",
    "    \n",
    "    test_dataset = NSCLCDataset(\n",
    "        data_root=data_root,\n",
    "        split_file=f\"{splits_dir}/test.txt\",\n",
    "        mode=mode\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Test rapide\n",
    "print(\"‚úÖ Dataset d√©fini!\")\n",
    "print(f\"   Mode: slice-wise (chaque slice = 1 √©chantillon)\")\n",
    "print(f\"   Structure: data/normalized/*.nii.gz + data/splits/*.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddee5205",
   "metadata": {},
   "source": [
    "## üèõÔ∏è U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac686ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        # Encoder\n",
    "        self.inc = DoubleConv(in_channels, features[0])\n",
    "        self.down1 = Down(features[0], features[1])\n",
    "        self.down2 = Down(features[1], features[2])\n",
    "        self.down3 = Down(features[2], features[3])\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.down4 = Down(features[3], features[3] * 2)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up1 = Up(features[3] * 2, features[3])\n",
    "        self.up2 = Up(features[3], features[2])\n",
    "        self.up3 = Up(features[2], features[1])\n",
    "        self.up4 = Up(features[1], features[0])\n",
    "        \n",
    "        # Output\n",
    "        self.outc = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        \n",
    "        return torch.sigmoid(self.outc(x))\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.contiguous().view(-1)\n",
    "        target = target.contiguous().view(-1)\n",
    "        intersection = (pred * target).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (pred.sum() + target.sum() + self.smooth)\n",
    "        return 1 - dice\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.bce = nn.BCELoss()\n",
    "        self.dice = DiceLoss()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        return self.alpha * self.bce(pred, target) + (1 - self.alpha) * self.dice(pred, target)\n",
    "\n",
    "# Test du mod√®le\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet(in_channels=1, out_channels=1).to(device)\n",
    "print(f\"‚úì Mod√®le cr√©√©: {sum(p.numel() for p in model.parameters()):,} param√®tres\")\n",
    "print(f\"‚úì Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47297252",
   "metadata": {},
   "source": [
    "## üéØ Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe99330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def calculate_metrics(pred, target, threshold=0.5):\n",
    "    \"\"\"Calcule Dice, IoU, etc.\"\"\"\n",
    "    pred_binary = (pred > threshold).float()\n",
    "    target_binary = target.float()\n",
    "    \n",
    "    intersection = (pred_binary * target_binary).sum()\n",
    "    union = pred_binary.sum() + target_binary.sum()\n",
    "    \n",
    "    dice = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "    iou = (intersection + 1e-6) / (union - intersection + 1e-6)\n",
    "    \n",
    "    return {\n",
    "        'dice': dice.item(),\n",
    "        'iou': iou.item()\n",
    "    }\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        device,\n",
    "        checkpoint_dir='checkpoints',\n",
    "        log_dir='logs'\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        \n",
    "        self.checkpoint_dir = Path(checkpoint_dir)\n",
    "        self.log_dir = Path(log_dir)\n",
    "        self.checkpoint_dir.mkdir(exist_ok=True)\n",
    "        self.log_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        self.history = {'train_loss': [], 'val_loss': [], 'val_dice': [], 'val_iou': []}\n",
    "        self.best_val_dice = 0.0\n",
    "    \n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc=f\"Epoch {epoch} [TRAIN]\")\n",
    "        for batch_idx, (images, masks) in enumerate(pbar):\n",
    "            images = images.to(self.device)\n",
    "            masks = masks.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        return total_loss / len(self.train_loader)\n",
    "    \n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        all_dice = []\n",
    "        all_iou = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(self.val_loader, desc=\"[VAL]\")\n",
    "            for images, masks in pbar:\n",
    "                images = images.to(self.device)\n",
    "                masks = masks.to(self.device)\n",
    "                \n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, masks)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                metrics = calculate_metrics(outputs, masks)\n",
    "                all_dice.append(metrics['dice'])\n",
    "                all_iou.append(metrics['iou'])\n",
    "        \n",
    "        return {\n",
    "            'loss': total_loss / len(self.val_loader),\n",
    "            'dice': np.mean(all_dice),\n",
    "            'iou': np.mean(all_iou)\n",
    "        }\n",
    "    \n",
    "    def save_checkpoint(self, epoch, val_metrics, is_best=False):\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'val_metrics': val_metrics,\n",
    "            'history': self.history\n",
    "        }\n",
    "        \n",
    "        torch.save(checkpoint, self.checkpoint_dir / 'latest_checkpoint.pth')\n",
    "        \n",
    "        if is_best:\n",
    "            torch.save(checkpoint, self.checkpoint_dir / 'best_model.pth')\n",
    "            print(f\"‚úì Best model saved (Dice: {val_metrics['dice']:.4f})\")\n",
    "    \n",
    "    def train(self, num_epochs, scheduler=None, early_stopping_patience=5):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Starting training for {num_epochs} epochs\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "        print(f\"{'='*50}\\n\")\n",
    "        \n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            # Train\n",
    "            train_loss = self.train_epoch(epoch)\n",
    "            \n",
    "            # Validate\n",
    "            val_metrics = self.validate()\n",
    "            \n",
    "            # Update history\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['val_loss'].append(val_metrics['loss'])\n",
    "            self.history['val_dice'].append(val_metrics['dice'])\n",
    "            self.history['val_iou'].append(val_metrics['iou'])\n",
    "            \n",
    "            # Print summary\n",
    "            print(f\"\\nEpoch {epoch}/{num_epochs}:\")\n",
    "            print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"  Val Loss: {val_metrics['loss']:.4f}\")\n",
    "            print(f\"  Val Dice: {val_metrics['dice']:.4f}\")\n",
    "            print(f\"  Val IoU: {val_metrics['iou']:.4f}\")\n",
    "            \n",
    "            # Save checkpoint\n",
    "            is_best = val_metrics['dice'] > self.best_val_dice\n",
    "            if is_best:\n",
    "                self.best_val_dice = val_metrics['dice']\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            self.save_checkpoint(epoch, val_metrics, is_best)\n",
    "            \n",
    "            # LR scheduler\n",
    "            if scheduler:\n",
    "                scheduler.step(val_metrics['dice'])\n",
    "            \n",
    "            # Early stopping\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f\"\\n‚ö†Ô∏è Early stopping triggered (patience={early_stopping_patience})\")\n",
    "                break\n",
    "        \n",
    "        # Save history\n",
    "        with open(self.log_dir / 'training_history.json', 'w') as f:\n",
    "            json.dump(self.history, f, indent=2)\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training completed!\")\n",
    "        print(f\"Best Val Dice: {self.best_val_dice:.4f}\")\n",
    "        print(f\"{'='*50}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65acad71",
   "metadata": {},
   "source": [
    "## üöÄ Lancement de l'entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3025369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BATCH_SIZE = 16 if torch.cuda.is_available() else 4  # Plus grand batch avec GPU\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 50  # Plus d'epochs possible avec GPU\n",
    "PATIENCE = 10\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Device: {device}\\n\")\n",
    "\n",
    "# Cr√©er les DataLoaders (avec les chemins corrects)\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    data_root=DATA_ROOT,\n",
    "    splits_dir=SPLITS_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=2,\n",
    "    mode='slice'\n",
    ")\n",
    "\n",
    "print(f\"\\nüì¶ Datasets charg√©s:\")\n",
    "print(f\"   Train: {len(train_loader.dataset)} slices\")\n",
    "print(f\"   Val: {len(val_loader.dataset)} slices\")\n",
    "print(f\"   Test: {len(test_loader.dataset)} slices\\n\")\n",
    "\n",
    "# Initialiser le mod√®le\n",
    "model = UNet(in_channels=1, out_channels=1).to(device)\n",
    "criterion = CombinedLoss(alpha=0.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='max',\n",
    "    factor=0.5,\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "# Cr√©er le trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    checkpoint_dir='checkpoints',\n",
    "    log_dir='logs'\n",
    ")\n",
    "\n",
    "# LANCER L'ENTRA√éNEMENT üöÄ\n",
    "trainer.train(\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    scheduler=scheduler,\n",
    "    early_stopping_patience=PATIENCE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0665bae",
   "metadata": {},
   "source": [
    "## üìä Visualisation des r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Charger l'historique\n",
    "with open('logs/training_history.json', 'r') as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "# Cr√©er les graphiques\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0, 0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training and Validation Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Dice Score\n",
    "axes[0, 1].plot(history['val_dice'], label='Val Dice', color='green', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Dice Score')\n",
    "axes[0, 1].set_title('Validation Dice Score')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# IoU Score\n",
    "axes[1, 0].plot(history['val_iou'], label='Val IoU', color='orange', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('IoU Score')\n",
    "axes[1, 0].set_title('Validation IoU Score')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Summary\n",
    "axes[1, 1].axis('off')\n",
    "summary_text = f\"\"\"\n",
    "TRAINING SUMMARY\n",
    "================\n",
    "\n",
    "Total Epochs: {len(history['train_loss'])}\n",
    "\n",
    "Final Train Loss: {history['train_loss'][-1]:.4f}\n",
    "Final Val Loss: {history['val_loss'][-1]:.4f}\n",
    "\n",
    "Best Val Dice: {max(history['val_dice']):.4f}\n",
    "Best Val IoU: {max(history['val_iou']):.4f}\n",
    "\n",
    "Model saved: checkpoints/best_model.pth\n",
    "\"\"\"\n",
    "axes[1, 1].text(0.1, 0.5, summary_text, fontsize=12, family='monospace',\n",
    "                verticalalignment='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úì Graphiques sauvegard√©s: training_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9843674",
   "metadata": {},
   "source": [
    "## üîç Test sur quelques pr√©dictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c540cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le meilleur mod√®le\n",
    "checkpoint = torch.load('checkpoints/best_model.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Prendre quelques exemples du test set\n",
    "test_iter = iter(test_loader)\n",
    "images, masks = next(test_iter)\n",
    "images = images.to(device)\n",
    "masks = masks.to(device)\n",
    "\n",
    "# Pr√©dictions\n",
    "with torch.no_grad():\n",
    "    predictions = model(images)\n",
    "\n",
    "# Visualiser\n",
    "fig, axes = plt.subplots(3, 5, figsize=(20, 12))\n",
    "for i in range(min(5, len(images))):\n",
    "    # Image CT\n",
    "    axes[0, i].imshow(images[i, 0].cpu(), cmap='gray')\n",
    "    axes[0, i].set_title('CT Image')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Ground Truth\n",
    "    axes[1, i].imshow(masks[i, 0].cpu(), cmap='gray')\n",
    "    axes[1, i].set_title('Ground Truth')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Pr√©diction\n",
    "    axes[2, i].imshow(predictions[i, 0].cpu(), cmap='gray')\n",
    "    dice = calculate_metrics(predictions[i:i+1], masks[i:i+1])['dice']\n",
    "    axes[2, i].set_title(f'Prediction (Dice: {dice:.3f})')\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('predictions_sample.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úì Pr√©dictions sauvegard√©es: predictions_sample.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac12b8b4",
   "metadata": {},
   "source": [
    "## üíæ T√©l√©charger les r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce4b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zipper tous les r√©sultats\n",
    "!zip -r results.zip checkpoints/ logs/ *.png\n",
    "\n",
    "# T√©l√©charger\n",
    "from google.colab import files\n",
    "files.download('results.zip')\n",
    "\n",
    "print(\"‚úì T√©l√©chargement lanc√©!\")\n",
    "print(\"\\nContenu du zip:\")\n",
    "print(\"  - checkpoints/best_model.pth (meilleur mod√®le)\")\n",
    "print(\"  - checkpoints/latest_checkpoint.pth (dernier checkpoint)\")\n",
    "print(\"  - logs/training_history.json (historique)\")\n",
    "print(\"  - training_results.png (graphiques)\")\n",
    "print(\"  - predictions_sample.png (exemples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c820b01a",
   "metadata": {},
   "source": [
    "## ‚úÖ R√©sum√© Final\n",
    "\n",
    "**Ce qui a √©t√© fait:**\n",
    "1. ‚úì Installation des d√©pendances\n",
    "2. ‚úì Upload des donn√©es normalis√©es\n",
    "3. ‚úì Cr√©ation du Dataset PyTorch\n",
    "4. ‚úì Cr√©ation du mod√®le U-Net\n",
    "5. ‚úì Entra√Ænement complet avec GPU\n",
    "6. ‚úì Visualisation des r√©sultats\n",
    "7. ‚úì T√©l√©chargement des checkpoints\n",
    "\n",
    "**Prochaines √©tapes sur ton PC:**\n",
    "1. D√©zippe `results.zip`\n",
    "2. Place `checkpoints/` dans ton projet\n",
    "3. Lance `python evaluate.py` pour l'√©valuation compl√®te\n",
    "4. Lance `python visualize_predictions.py` pour plus de visualisations\n",
    "\n",
    "**Temps total:** ~10-15 minutes avec GPU T4 üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
