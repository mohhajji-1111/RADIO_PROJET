{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92654a32",
   "metadata": {},
   "source": [
    "## üì¶ Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895057dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Add dataset code to path\n",
    "code_dir = '/kaggle/input/nsclc-multiorgan-segmentation/code'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# Import custom modules\n",
    "from dataset_multi_organ import MultiOrganDataset\n",
    "from unet_multi_organ import UNetMultiOrgan\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e4bca1",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960ad954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_ROOT = '/kaggle/input/nsclc-multiorgan-segmentation'\n",
    "OUTPUT_DIR = Path('/kaggle/working')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Training hyperparameters\n",
    "CONFIG = {\n",
    "    'batch_size': 8,\n",
    "    'num_epochs': 50,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_workers': 2,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'patience': 10,  # Early stopping\n",
    "    'in_channels': 1,\n",
    "    'out_channels': 8,\n",
    "    'bilinear': False\n",
    "}\n",
    "\n",
    "# Organ names\n",
    "ORGAN_NAMES = {\n",
    "    0: 'Background',\n",
    "    1: 'GTV',\n",
    "    2: 'PTV',\n",
    "    3: 'Right_Lung',\n",
    "    4: 'Left_Lung',\n",
    "    5: 'Heart',\n",
    "    6: 'Esophagus',\n",
    "    7: 'Spinal_Cord'\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801de167",
   "metadata": {},
   "source": [
    "## üìä Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca53ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading datasets...\")\n",
    "\n",
    "train_dataset = MultiOrganDataset(\n",
    "    data_root=DATA_ROOT,\n",
    "    split='train',\n",
    "    slice_wise=True\n",
    ")\n",
    "\n",
    "val_dataset = MultiOrganDataset(\n",
    "    data_root=DATA_ROOT,\n",
    "    split='val',\n",
    "    slice_wise=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Train dataset: {len(train_dataset)} slices\")\n",
    "print(f\"‚úÖ Val dataset: {len(val_dataset)} slices\")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Train batches: {len(train_loader)}\")\n",
    "print(f\"‚úÖ Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818a9a9b",
   "metadata": {},
   "source": [
    "## üîç Visualize Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3338dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample\n",
    "sample_batch = next(iter(train_loader))\n",
    "sample_image = sample_batch['image'][0, 0].cpu().numpy()\n",
    "sample_mask = sample_batch['mask'][0].cpu().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(sample_image, cmap='gray')\n",
    "axes[0].set_title('CT Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(sample_mask, cmap='tab10', vmin=0, vmax=7)\n",
    "axes[1].set_title('Ground Truth Mask')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(sample_image, cmap='gray')\n",
    "axes[2].imshow(sample_mask, cmap='tab10', vmin=0, vmax=7, alpha=0.5)\n",
    "axes[2].set_title('Overlay')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'sample_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nImage shape: {sample_batch['image'].shape}\")\n",
    "print(f\"Mask shape: {sample_batch['mask'].shape}\")\n",
    "print(f\"Unique labels: {torch.unique(sample_batch['mask']).tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dbbebb",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Calculate Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98edf159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(dataset, num_classes=8, max_samples=1000):\n",
    "    \"\"\"Calculate class weights using sqrt inverse frequency.\"\"\"\n",
    "    print(f\"Calculating class weights (sampling {max_samples} slices)...\")\n",
    "    \n",
    "    class_counts = np.zeros(num_classes, dtype=np.int64)\n",
    "    \n",
    "    indices = np.random.choice(len(dataset), size=min(max_samples, len(dataset)), replace=False)\n",
    "    \n",
    "    for idx in tqdm(indices):\n",
    "        mask = dataset[idx]['mask'].numpy()\n",
    "        unique, counts = np.unique(mask, return_counts=True)\n",
    "        for label, count in zip(unique, counts):\n",
    "            if label < num_classes:\n",
    "                class_counts[label] += count\n",
    "    \n",
    "    # Sqrt inverse frequency\n",
    "    total_pixels = class_counts.sum()\n",
    "    class_weights = np.sqrt(total_pixels / (class_counts + 1e-5))\n",
    "    class_weights = class_weights / class_weights.sum() * num_classes\n",
    "    \n",
    "    print(\"\\nClass weights:\")\n",
    "    for i in range(num_classes):\n",
    "        freq = class_counts[i] / total_pixels * 100\n",
    "        print(f\"  {ORGAN_NAMES[i]:15s}: weight={class_weights[i]:.4f}, freq={freq:.2f}%\")\n",
    "    \n",
    "    return torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "# Calculate or load weights\n",
    "weights_path = OUTPUT_DIR / 'class_weights.json'\n",
    "if weights_path.exists():\n",
    "    print(\"Loading cached class weights...\")\n",
    "    with open(weights_path) as f:\n",
    "        class_weights = torch.tensor(json.load(f), dtype=torch.float32)\n",
    "else:\n",
    "    class_weights = calculate_class_weights(train_dataset)\n",
    "    with open(weights_path, 'w') as f:\n",
    "        json.dump(class_weights.tolist(), f)\n",
    "\n",
    "class_weights = class_weights.to(CONFIG['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8b79f6",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetMultiOrgan(\n",
    "    in_channels=CONFIG['in_channels'],\n",
    "    out_channels=CONFIG['out_channels'],\n",
    "    bilinear=CONFIG['bilinear']\n",
    ").to(CONFIG['device'])\n",
    "\n",
    "# Count parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\n‚úÖ Model created: {num_params:,} parameters ({num_params*4/1e6:.2f} MB)\")\n",
    "\n",
    "# Test forward pass\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randn(2, 1, 256, 256).to(CONFIG['device'])\n",
    "    test_output = model(test_input)\n",
    "    print(f\"Test forward pass: {test_input.shape} ‚Üí {test_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07457da7",
   "metadata": {},
   "source": [
    "## üìâ Define Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8a9568",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, num_classes=8, smooth=1.0):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        pred_softmax = torch.softmax(pred, dim=1)\n",
    "        target_one_hot = torch.nn.functional.one_hot(target, self.num_classes).permute(0, 3, 1, 2).float()\n",
    "        \n",
    "        intersection = (pred_softmax * target_one_hot).sum(dim=(2, 3))\n",
    "        union = pred_softmax.sum(dim=(2, 3)) + target_one_hot.sum(dim=(2, 3))\n",
    "        \n",
    "        dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
    "        return 1.0 - dice.mean()\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, class_weights, num_classes=8):\n",
    "        super().__init__()\n",
    "        self.ce_loss = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        self.dice_loss = DiceLoss(num_classes=num_classes)\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        ce = self.ce_loss(pred, target)\n",
    "        dice = self.dice_loss(pred, target)\n",
    "        return 0.5 * ce + 0.5 * dice\n",
    "\n",
    "criterion = CombinedLoss(class_weights=class_weights, num_classes=CONFIG['out_channels'])\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'])\n",
    "\n",
    "print(\"‚úÖ Loss function: CombinedLoss (0.5 * CrossEntropy + 0.5 * Dice)\")\n",
    "print(f\"‚úÖ Optimizer: Adam (lr={CONFIG['learning_rate']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d67ba22",
   "metadata": {},
   "source": [
    "## üéì Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5267b872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dice_score(pred, target, num_classes=8):\n",
    "    \"\"\"Compute Dice score per class.\"\"\"\n",
    "    pred_labels = torch.argmax(pred, dim=1)\n",
    "    dice_scores = []\n",
    "    \n",
    "    for c in range(1, num_classes):  # Skip background\n",
    "        pred_c = (pred_labels == c).float()\n",
    "        target_c = (target == c).float()\n",
    "        \n",
    "        intersection = (pred_c * target_c).sum()\n",
    "        union = pred_c.sum() + target_c.sum()\n",
    "        \n",
    "        if union > 0:\n",
    "            dice = (2.0 * intersection) / union\n",
    "            dice_scores.append(dice.item())\n",
    "        else:\n",
    "            dice_scores.append(0.0)\n",
    "    \n",
    "    return np.mean(dice_scores)\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_dice = 0.0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for batch in pbar:\n",
    "        images = batch['image'].to(device)\n",
    "        masks = batch['mask'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        dice = compute_dice_score(outputs, masks)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_dice += dice\n",
    "        \n",
    "        pbar.set_postfix({'loss': loss.item(), 'dice': dice})\n",
    "    \n",
    "    return total_loss / len(loader), total_dice / len(loader)\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_dice = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc='Validation')\n",
    "        for batch in pbar:\n",
    "            images = batch['image'].to(device)\n",
    "            masks = batch['mask'].to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            dice = compute_dice_score(outputs, masks)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_dice += dice\n",
    "            \n",
    "            pbar.set_postfix({'loss': loss.item(), 'dice': dice})\n",
    "    \n",
    "    return total_loss / len(loader), total_dice / len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a0295b",
   "metadata": {},
   "source": [
    "## üöÄ Main Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e9192",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ STARTING TRAINING\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_dice': [],\n",
    "    'val_loss': [],\n",
    "    'val_dice': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(CONFIG['num_epochs']):\n",
    "    print(f\"\\nEpoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_dice = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, CONFIG['device']\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_dice = validate(\n",
    "        model, val_loader, criterion, CONFIG['device']\n",
    "    )\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_dice'].append(train_dice)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_dice'].append(val_dice)\n",
    "    \n",
    "    print(f\"\\nTrain Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Dice: {val_dice:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_dice': val_dice\n",
    "        }, OUTPUT_DIR / 'best_model.pth')\n",
    "        print(\"‚úÖ Saved best model\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"Patience: {patience_counter}/{CONFIG['patience']}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= CONFIG['patience']:\n",
    "        print(f\"\\n‚ö†Ô∏è Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "    \n",
    "    # Save checkpoint every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, OUTPUT_DIR / f'checkpoint_epoch_{epoch+1}.pth')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ TRAINING COMPLETED\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bc2805",
   "metadata": {},
   "source": [
    "## üìä Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57efe66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training & Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Dice\n",
    "axes[1].plot(history['train_dice'], label='Train Dice', linewidth=2)\n",
    "axes[1].plot(history['val_dice'], label='Val Dice', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Dice Score', fontsize=12)\n",
    "axes[1].set_title('Training & Validation Dice', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Best Val Loss: {min(history['val_loss']):.4f}\")\n",
    "print(f\"üìä Best Val Dice: {max(history['val_dice']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8142069f",
   "metadata": {},
   "source": [
    "## üîÆ Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8aa35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(OUTPUT_DIR / 'best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Get samples\n",
    "val_batch = next(iter(val_loader))\n",
    "images = val_batch['image'].to(CONFIG['device'])\n",
    "masks = val_batch['mask'].cpu().numpy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "\n",
    "images_np = images.cpu().numpy()\n",
    "\n",
    "# Plot 4 samples\n",
    "fig, axes = plt.subplots(4, 3, figsize=(12, 16))\n",
    "\n",
    "for i in range(min(4, len(images))):\n",
    "    # CT\n",
    "    axes[i, 0].imshow(images_np[i, 0], cmap='gray')\n",
    "    axes[i, 0].set_title('CT Image', fontsize=10)\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Ground truth\n",
    "    axes[i, 1].imshow(masks[i], cmap='tab10', vmin=0, vmax=7)\n",
    "    axes[i, 1].set_title('Ground Truth', fontsize=10)\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Prediction\n",
    "    axes[i, 2].imshow(preds[i], cmap='tab10', vmin=0, vmax=7)\n",
    "    axes[i, 2].set_title('Prediction', fontsize=10)\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'predictions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Predictions visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44885947",
   "metadata": {},
   "source": [
    "## üíæ Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94921b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history\n",
    "with open(OUTPUT_DIR / 'training_history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìÅ SAVED FILES:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"  ‚Ä¢ best_model.pth - Best model checkpoint\")\n",
    "print(f\"  ‚Ä¢ training_curves.png - Loss & Dice plots\")\n",
    "print(f\"  ‚Ä¢ predictions.png - Sample predictions\")\n",
    "print(f\"  ‚Ä¢ training_history.json - Full training history\")\n",
    "print(f\"  ‚Ä¢ class_weights.json - Class weights for reuse\")\n",
    "print(\"\\n‚úÖ Training pipeline completed successfully!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
