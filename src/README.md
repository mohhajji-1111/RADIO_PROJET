# ğŸ“¦ Source Code

Core implementation of the NSCLC Multi-Organ Segmentation project.

## ğŸ“ Structure

```
src/
â”œâ”€â”€ config/          # Configuration files
â”‚   â”œâ”€â”€ params.yaml      # Training parameters
â”‚   â”œâ”€â”€ paths.yaml       # Data paths
â”‚   â””â”€â”€ environment.yaml # Conda environment
â”‚
â”œâ”€â”€ data/            # Data loading
â”‚   â””â”€â”€ dataset.py       # PyTorch Dataset class
â”‚
â”œâ”€â”€ models/          # Neural network architectures
â”‚   â””â”€â”€ unet.py          # U-Net implementation
â”‚
â”œâ”€â”€ preprocessing/   # Data preprocessing
â”‚   â”œâ”€â”€ convert_dicom_to_nifti.py
â”‚   â”œâ”€â”€ extract_mask_from_rtstruct.py
â”‚   â”œâ”€â”€ normalize_data.py
â”‚   â””â”€â”€ split_dataset.py
â”‚
â”œâ”€â”€ training/        # Training utilities
â”‚   â”œâ”€â”€ trainer.py       # Training loop
â”‚   â”œâ”€â”€ evaluate.py      # Metrics calculation
â”‚   â””â”€â”€ visualize.py     # Result visualization
â”‚
â””â”€â”€ visualization/   # Visualization tools
    â””â”€â”€ visualize.py
```

## ğŸ”§ Key Components

### U-Net Model (`models/unet.py`)
- Encoder-decoder architecture
- Skip connections
- Multi-class output

### Dataset (`data/dataset.py`)
- Lazy loading for memory efficiency
- Data augmentation
- Normalized HU values

### Trainer (`training/trainer.py`)
- Training loop with validation
- Checkpoint management
- Early stopping

## ğŸ“ Usage

```python
from src.models.unet import UNet
from src.data.dataset import NSCLCDataset
from src.training.trainer import Trainer

# Initialize
model = UNet(in_channels=1, out_channels=8)
dataset = NSCLCDataset(data_dir='DATA/processed')
trainer = Trainer(model, dataset)

# Train
trainer.train(epochs=50)
```
